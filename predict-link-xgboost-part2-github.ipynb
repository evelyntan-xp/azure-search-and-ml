{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #2:  Deploy model as an Azure Container Instances (ACI) webservice\n",
    "\n",
    "In the [Tutorial #1](predict-emailservice-part1.ipynb), you trained machine learning models and then registered a model in your workspace on the cloud.\n",
    "This tutorial will go through the steps to deploy the model as an [Azure Container Instances](https://docs.microsoft.com/azure/container-instances/) (ACI) webservice, a Docker image that encapsulates the scoring logic and the model itself. \n",
    "\n",
    "The codes here were tested using Azure ML SDK version:\n",
    "- 1.6.0\n",
    "- 1.3.0\n",
    "- 1.0.72 on Microsoft Azure Notebooks with Python 3.6 kernel         \n",
    "        \n",
    "In this tutorial, you use Azure Machine Learning service to:\n",
    "* Retrieve the model from your workspace\n",
    "* Create a scoring script\n",
    "* Deploy the model as an ACI webservice\n",
    "* Test the deployed model\n",
    "\n",
    "ACI is a great solution for testing and understanding the workflow. For scalable production deployments, consider using Azure Kubernetes Service. For more information, see [how to deploy and where](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where).\n",
    "\n",
    "\n",
    "\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Azure Machine Learning Workspace\n",
    "\n",
    "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file **config.json** and loads the details into an object named `workspace`.\n",
    "\n",
    "If you see this message:\n",
    "\"Performing interactive authentication. Please follow the instructions on the terminal.\n",
    "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code &lt;token\\&gt; to authenticate.\"\n",
    "    \n",
    "Click on the link and use the &lt;token\\&gt; given to authenticate. After authenticated, run this script again to get load the Workspace.&lt;/token\\&gt;&lt;/token\\&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "load workspace"
    ]
   },
   "outputs": [],
   "source": [
    "# Load workspace configuration from the config.json file in the current folder.\n",
    "from azureml.core import Workspace\n",
    "workspace = Workspace.from_config()\n",
    "# print(workspace.name, workspace.location, workspace.resource_group, workspace.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Azure Machine Learning SDK for Python \n",
    "\n",
    "This step is to test you have installed Azure Machine Learning SDK for Python. Most of the coding will required the use of the Azure ML SDK. \n",
    "\n",
    "Display the Azure Machine Learning SDK version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.24.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "# check core SDK version number (need Python 3.6 kernel if you run this in Microsoft Azure Notebooks)\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model locally\n",
    "\n",
    "Before deploying, make sure your model is working locally by:\n",
    "* Loading test data\n",
    "* Predicting test data\n",
    "* Examining the confusion matrix\n",
    "\n",
    "### Load test data\n",
    " \n",
    "You can create your test data, but for simplicity this tutorial will only re-use the same dataset from Tutorial #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_search_client import azure_search_client as azs_client \n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent\n",
    "import datetime\n",
    "from itertools import chain\n",
    "import random\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(service, query):\n",
    "    search_request_body = {\n",
    "        \"search\": query,\n",
    "        \"featuresMode\": \"enabled\",\n",
    "        \"scoringStatistics\": \"global\",\n",
    "        \"count\": \"true\"\n",
    "    }\n",
    "    \n",
    "    return service.search(search_request_body)\n",
    "\n",
    "def get_features(service, query):\n",
    "    \n",
    "    search_results = get_search_results(service, query.lower())\n",
    "\n",
    "    # this will flatten the search json response into a panda dataframe\n",
    "    azs_features = json_normalize(search_results)\n",
    "\n",
    "    return azs_features\n",
    "\n",
    "def retrieve_from_search(query, sessionid, azs_service):\n",
    "    \n",
    "    ## Call the api service to retrieve json format data\n",
    "    json_search_results = get_search_results(azs_service, query)\n",
    "    \n",
    "    ## Flatten the json format data into pandas dataframe\n",
    "    search_results = json_normalize(json_search_results).fillna(0)\n",
    "    search_results = search_results.fillna(0).sort_values(['@search.score'], ascending=False)\n",
    "    search_results['query'] = query.lower()\n",
    "    search_results['sessionid'] = sessionid\n",
    "    print('{} rows for query : {}'.format(search_results.shape[0], query))\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "def dcg_score(y_true, y_score, k=50, gains=\"exponential\"):\n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank k\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    gains : str\n",
    "        Whether gains should be \"exponential\" (default) or \"linear\".\n",
    "    Returns\n",
    "    -------\n",
    "    DCG @k : float\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_true - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_true\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "\n",
    "    # highest rank is 1 so +2 instead of +1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=50, gains=\"exponential\"):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank k\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    gains : str\n",
    "        Whether gains should be \"exponential\" (default) or \"linear\".\n",
    "    Returns\n",
    "    -------\n",
    "    NDCG @k : float\n",
    "    \"\"\"\n",
    "    best = dcg_score(y_true, y_true, k, gains)\n",
    "    actual = dcg_score(y_true, y_score, k, gains)\n",
    "    return actual / best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code connects to the api service using the config json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows for query : powershell\n"
     ]
    }
   ],
   "source": [
    "azs_service = azs_client.from_json('api_config.json')\n",
    "azs_service\n",
    "\n",
    "# Create the necessary queries to create dataset\n",
    "query_input = ['powershell']\n",
    "\n",
    "demo_query_dataset = pd.DataFrame()\n",
    "sessionid =1\n",
    "for query in query_input:\n",
    "    demo_query_dataset = pd.concat([demo_query_dataset, retrieve_from_search(query, sessionid, azs_service)])\n",
    "    sessionid+=1\n",
    "    \n",
    "demo_query_dataset['grade'] = demo_query_dataset['grade'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the model\n",
    "\n",
    "You registered a model in your workspace in tutorial1. Now, load this workspace and download the model to your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(workspace=Workspace.create(name='csidmlws', subscription_id='ebe8d9fa-67d0-4af1-bce2-4a5b07e50a42', resource_group='cmt-202011001'), name=predict-link-xgboostmodel, id=predict-link-xgboostmodel:5, version=5, tags={'Setting up xgb params': \"{'objective': 'rank:ndcg', 'learning_rate': 0.5, 'min_child_weight': 0.1, 'max_depth': 10, 'n_estimators': 200}\", 'XGboost NDCG is': '0.9783009542123144', 'Azure Search NDCG is': '0.7557246194876953'}, properties={})\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "import os \n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "\n",
    "model=Model(workspace,'predict-link-xgboostmodel') # Default will get the latest version.\n",
    "\n",
    "model.download(target_dir=os.getcwd(), exist_ok=True)\n",
    "print(model)\n",
    "\n",
    "# # Get the model file path.\n",
    "file_path = os.path.join(os.getcwd(), \"predict-link-xgboostmodel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data\n",
    "\n",
    "Feed the test dataset to the model to get predictions.\n",
    "\n",
    "import joblib to load file path of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "          colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "          importance_type='gain', interaction_constraints='', learning_rate=0.5,\n",
      "          max_delta_step=0, max_depth=10, min_child_weight=0.1, missing=nan,\n",
      "          monotone_constraints='()', n_estimators=200, n_jobs=2,\n",
      "          num_parallel_tree=1, objective='rank:ndcg', random_state=0,\n",
      "          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "          tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Score\n",
      "0.5692044172607783 0.988999019408289\n"
     ]
    }
   ],
   "source": [
    "import joblib # Use this to load the model that was created on local in Tutorial #1\n",
    "xgbmodel = joblib.load(file_path)\n",
    "print(xgbmodel)\n",
    "features = ['@search.features.keyphrases.similarityScore',\n",
    "   '@search.features.keyphrases.termFrequency',\n",
    "   '@search.features.keyphrases.uniqueTokenMatches',\n",
    "   '@search.features.query.similarityScore',\n",
    "   '@search.features.query.termFrequency',\n",
    "   '@search.features.query.uniqueTokenMatches',\n",
    "   '@search.features.url.similarityScore',\n",
    "   '@search.features.url.termFrequency',\n",
    "   '@search.features.url.uniqueTokenMatches', '@search.score']\n",
    "    \n",
    "y_hat = xgbmodel.predict(demo_query_dataset[features])\n",
    "\n",
    "output_score = pd.DataFrame(y_hat)\n",
    "output_score.columns=['score']\n",
    "output_score_sorted = output_score.sort_values('score', ascending = True).reset_index()\n",
    "num_rows = output_score_sorted.shape[0]\n",
    "demo_query_dataset['index'] = demo_query_dataset.index\n",
    "check_acc = demo_query_dataset.merge(output_score_sorted, on = ['index'])\n",
    "\n",
    "azs_search = check_acc.sort_values(['@search.score'], ascending = False)\\\n",
    "[['url', 'grade']].reset_index(drop = True)\n",
    "xgboost = check_acc.sort_values(['sessionid','score'], ascending = False)\\\n",
    "[['url','grade']].reset_index(drop = True)\n",
    "\n",
    "xgboost_ndcg = ndcg_score(check_acc.sort_values(['grade'], ascending = False).grade\n",
    "           , xgboost.grade)\n",
    "\n",
    "azs_search_ndcg = ndcg_score(check_acc.sort_values(['grade'], ascending = False).grade\n",
    "           , azs_search.grade)\n",
    "\n",
    "print('Score')\n",
    "print(azs_search_ndcg, xgboost_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our demo_query_dataset into a JSON format as Azure Containter Instance read in data in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "0.5692044172607783 0.988999019408289\n"
     ]
    }
   ],
   "source": [
    "json_data = demo_query_dataset[features].to_json(orient='records')\n",
    "data = pd.read_json(json_data, orient='records')\n",
    "\n",
    "prediction_score = xgbmodel.predict(data)\n",
    "output_score = pd.DataFrame(prediction_score)\n",
    "output_score.columns=['score']\n",
    "output_score_sorted = output_score.sort_values('score', ascending = False).reset_index()\n",
    "\n",
    "num_rows = output_score_sorted.shape[0]\n",
    "demo_query_dataset['index'] = demo_query_dataset.index\n",
    "check_acc = demo_query_dataset.merge(output_score_sorted, on = ['index'])\n",
    "\n",
    "azs_search = check_acc.sort_values(['@search.score'], ascending = False)\\\n",
    "[['url', 'grade']].reset_index(drop = True)\n",
    "xgboost = check_acc.sort_values(['sessionid','score'], ascending = False)\\\n",
    "[['url','grade']].reset_index(drop = True)\n",
    "\n",
    "xgboost_ndcg = ndcg_score(check_acc.sort_values(['grade'], ascending = False).grade\n",
    "           , xgboost.grade)\n",
    "\n",
    "azs_search_ndcg = ndcg_score(check_acc.sort_values(['grade'], ascending = False).grade\n",
    "           , azs_search.grade)\n",
    "\n",
    "print('Score')\n",
    "print(azs_search_ndcg, xgboost_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model\n",
    "\n",
    "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI. \n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script to show how to use the model\n",
    "* An environment file to show what packages need to be installed\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before\n",
    "\n",
    "Note: the deployed web service can be found in your Workspace &gt; Deployments.\n",
    "\n",
    "### Create a scoring script\n",
    "\n",
    "You must provide two required functions in the scoring script:\n",
    "* The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started. \n",
    "\n",
    "* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score_link_xgboost.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score_link_xgboost.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('predict-link-xgboostmodel')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "\n",
    "    data = pd.read_json(raw_data, orient='records')\n",
    "    prediction_score = model.predict(data)\n",
    "    output_score = pd.DataFrame(prediction_score)\n",
    "    output_score.columns=['score']\n",
    "    output_score_sorted = output_score.sort_values('score', ascending = False).reset_index()\n",
    "    \n",
    "    return output_score_sorted.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as an ACI webservice\n",
    "The deployment goes through these steps:\n",
    "1. Build an image using:\n",
    "   * The scoring file (`score_link_xgboost.py`)\n",
    "   * The environment and resources required\n",
    "   * The model file\n",
    "1. Register that image under the workspace. \n",
    "1. Send the image to the ACI container.\n",
    "1. Start up a container in ACI using the image.\n",
    "1. Get the web service HTTP endpoint.\n",
    "\n",
    "Note:\n",
    "If you see \"ERROR - Error, there is already a service with name xgboost-link-svc found in workspace <your workspace name>\", \n",
    "go to your **Azure ML Workspace &gt; Deployments**, where you can delete it if you need to recreate the service.\n",
    "\n",
    "\n",
    "This step may take a while to start after you run the cell, you will see the message \"Running\" appearing when it starts and will take few minutes to complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-04-26 01:22:04+00:00 Creating Container Registry if not exists.\n",
      "2021-04-26 01:22:04+00:00 Registering the environment.\n",
      "2021-04-26 01:22:05+00:00 Use the existing image.\n",
      "2021-04-26 01:22:06+00:00 Generating deployment configuration.\n",
      "2021-04-26 01:22:06+00:00 Submitting deployment to compute..\n",
      "2021-04-26 01:22:12+00:00 Checking the status of deployment xgboost-link-svc..\n",
      "2021-04-26 01:24:43+00:00 Checking the status of inference endpoint xgboost-link-svc.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 422 ms, sys: 24.3 ms, total: 446 ms\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Configure the environment to run the scoring script.\n",
    "# You definitley need azureml-sdk, azureml-defaults and joblib\n",
    "env = Environment('my_env_xgboost')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-sdk','azureml-defaults','xgboost==1.3.3','joblib==1.0.1'])\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Combine scoring script & environment in Inference configuration\n",
    "inference_config = InferenceConfig(entry_script=\"score_link_xgboost.py\", environment=env)\n",
    "\n",
    "# Set deployment configuration. While it depends on your model, the default of 1 core and 1 gigabyte of RAM \n",
    "# is usually sufficient for many models. If you feel you need more later, you would have to recreate the \n",
    "# image and redeploy the service.\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"Link Ranking\",  \"method\" : \"xgboost\"}, \n",
    "                                               description='Predict link with xgboost')\n",
    "\n",
    "\n",
    "# Define the model, inference, & deployment configuration and web service name and location to deploy\n",
    "service = Model.deploy(\n",
    "    workspace = workspace,\n",
    "    name = \"xgboost-link-svc\",\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code should be run immediately after the above cell in order to capture the logs of the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26T01:24:33,388038700+00:00 - iot-server/run \n",
      "2021-04-26T01:24:33,389407800+00:00 - rsyslog/run \n",
      "2021-04-26T01:24:33,397639600+00:00 - gunicorn/run \n",
      "2021-04-26T01:24:33,425529800+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_5a2612773d8ca70946c62488132c4632/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_5a2612773d8ca70946c62488132c4632/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_5a2612773d8ca70946c62488132c4632/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_5a2612773d8ca70946c62488132c4632/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_5a2612773d8ca70946c62488132c4632/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-26T01:24:33,786495100+00:00 - iot-server/finish 1 0\n",
      "2021-04-26T01:24:33,788675500+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (71)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 100\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-04-26 01:24:37,515 | root | INFO | Starting up app insights client\n",
      "2021-04-26 01:24:37,515 | root | INFO | Starting up request id generator\n",
      "2021-04-26 01:24:37,516 | root | INFO | Starting up app insight hooks\n",
      "2021-04-26 01:24:37,516 | root | INFO | Invoking user's init function\n",
      "2021-04-26 01:24:37,545 | root | INFO | Users's init has completed successfully\n",
      "2021-04-26 01:24:37,547 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-04-26 01:24:37,547 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-04-26 01:24:37,549 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-04-26 01:24:43,357 | root | INFO | Swagger file not present\n",
      "2021-04-26 01:24:43,357 | root | INFO | 404\n",
      "127.0.0.1 - - [26/Apr/2021:01:24:43 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-04-26 01:24:45,133 | root | INFO | Swagger file not present\n",
      "2021-04-26 01:24:45,134 | root | INFO | 404\n",
      "127.0.0.1 - - [26/Apr/2021:01:24:45 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Webservice(workspace=workspace, name='xgboost-link-svc')\n",
    "# print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployed model\n",
    "\n",
    "Test the deployed model with another test data using another query. For simplicity, the same\n",
    "training data is used.\n",
    "\n",
    "The following code goes through these steps:\n",
    "1. Send the data as a JSON array to the web service hosted in ACI. \n",
    "\n",
    "1. Use the SDK's `run` API to invoke the service. You can also make raw calls using any HTTP tool such as curl.\n",
    "\n",
    "Run below code cell few times to see the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.597492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.208377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.903777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.903777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.201843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.783272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.783272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.290542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.290542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.290542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     score\n",
       "0      6  5.597492\n",
       "1      2  3.208377\n",
       "2      7  0.903777\n",
       "3      8  0.903777\n",
       "4      9 -0.201843\n",
       "5      0 -0.783272\n",
       "6      1 -0.783272\n",
       "7      3 -1.290542\n",
       "8      4 -1.290542\n",
       "9      5 -1.290542"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from azure_search_client import azure_search_client as azs_client \n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Converting user query into JSON in order to push to ACI\n",
    "json_data = demo_query_dataset[features].to_json(orient='records')\n",
    "\n",
    "# Push JSON data into ACI to rerank the result which will return a json. \"service\" is the endpoint\n",
    "result = service.run(input_data=json_data)\n",
    "result = pd.read_json(result, orient='records')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass **result.url** back to your user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azs_search_url</th>\n",
       "      <th>azs_search_grade</th>\n",
       "      <th>xgboost_url</th>\n",
       "      <th>xgboost_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/sc...</td>\n",
       "      <td>7</td>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/sc...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/sc...</td>\n",
       "      <td>6</td>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/</td>\n",
       "      <td>9</td>\n",
       "      <td>https://docs.microsoft.com/en-us/windows-serve...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/sc...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/az...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://docs.microsoft.com/en-us/powershell/sc...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://docs.microsoft.com/en-us/virtualizatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      azs_search_url  azs_search_grade  \\\n",
       "0  https://docs.microsoft.com/en-us/powershell/sc...                 7   \n",
       "1  https://docs.microsoft.com/en-us/powershell/sc...                 6   \n",
       "2       https://docs.microsoft.com/en-us/powershell/                 9   \n",
       "3  https://docs.microsoft.com/en-us/powershell/sc...                 5   \n",
       "4  https://docs.microsoft.com/en-us/powershell/sc...                 4   \n",
       "\n",
       "                                         xgboost_url  xgboost_grade  \n",
       "0  https://docs.microsoft.com/en-us/powershell/sc...             10  \n",
       "1       https://docs.microsoft.com/en-us/powershell/              9  \n",
       "2  https://docs.microsoft.com/en-us/windows-serve...              8  \n",
       "3  https://docs.microsoft.com/en-us/powershell/az...              3  \n",
       "4  https://docs.microsoft.com/en-us/virtualizatio...              1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_query_dataset = demo_query_dataset.merge(result, on = ['index']) \n",
    "azs_search = demo_query_dataset.sort_values(['@search.score'], ascending = False)\\\n",
    "[['url', 'grade']].reset_index(drop = True)\n",
    "xgboost = demo_query_dataset.sort_values(['score'], ascending = False)\\\n",
    "[['url','grade']].reset_index(drop = True)\n",
    "\n",
    "compare_df = pd.concat([azs_search[['url', 'grade']], xgboost[['url', 'grade']]], axis = 1)\n",
    "compare_df.columns = ['azs_search_url','azs_search_grade','xgboost_url','xgboost_grade']\n",
    "compare_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send raw HTTP request to test the web service. Run below code cell few times to see different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://5a8f0051-0cbf-4522-ab66-97fae0522a11.southeastasia.azurecontainer.io/score\n",
      "prediction: \"[{\\\"index\\\":6,\\\"score\\\":5.597492218},{\\\"index\\\":2,\\\"score\\\":3.2083768845},{\\\"index\\\":7,\\\"score\\\":0.9037772417},{\\\"index\\\":8,\\\"score\\\":0.9037772417},{\\\"index\\\":9,\\\"score\\\":-0.2018429041},{\\\"index\\\":0,\\\"score\\\":-0.783272326},{\\\"index\\\":1,\\\"score\\\":-0.783272326},{\\\"index\\\":3,\\\"score\\\":-1.2905415297},{\\\"index\\\":4,\\\"score\\\":-1.2905415297},{\\\"index\\\":5,\\\"score\\\":-1.2905415297}]\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "input_data = json_data \n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "# print(\"input data:\", input_data)\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "To keep the resource group and workspace for other tutorials and exploration, you can delete only the ACI deployment using this API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually delete the deployed web service which can be found in your **Azure ML Workspace &gt; Deployments**.\n",
    "\n",
    "If you're not going to use what you've created here, delete the resources you just created so you don't incur any charges. "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "roastala"
   }
  ],
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "roastala",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
