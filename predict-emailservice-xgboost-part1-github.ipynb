{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #1: Model training with Azure Machine Learning\n",
    "\n",
    "In this tutorial, you will train a machine learning model on local and Azure compute resources. You will explore the Azure Machine Learning service and the Azure ML SDK for Python. \n",
    "This notebook serves as a quick start to hands-on Azure Machine Learning service. \n",
    "\n",
    "Before you start this tutorial, you need to create a workspace in the Azure portal first.\n",
    "[Create and manage Azure Machine Learning workspaces in the Azure portal](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace)\n",
    "\n",
    "The following are covered in this tutorial:\n",
    "* Extract data from Azure Search Service\n",
    "* Train a xgboost model on local machine and on Azure compute resources\n",
    "* Register the model in Azure Machine Learning Workspace\n",
    "\n",
    "If you are trying out this tutorial for the first time, please run the code cells in this tutorial sequentially.\n",
    "Tutorial #2 will cover the basics of deploying a model. \n",
    "\n",
    "## References\n",
    "\n",
    "[Azure Machine Learning documentation](https://github.com/leekokhow/azureml/blob/master/predict-employee-retention-part1-training.ipynb).\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your development environment\n",
    "\n",
    "### Dependencies required for local machine setup in order to use Azure ML SDK.\n",
    "\n",
    "Step 1. You need to create a [free Azure account](https://azure.microsoft.com/en-gb/free/) first. This tutorial will use Anaconda on your local machine to connect to your Azure account.\n",
    "\n",
    "Step 2. This notebook was tested in Anaconda Jupyter Notebook. \n",
    "Once you have installed Anaconda on your machine, run the following pip commands to download these packages into Anaconda:\n",
    "    \n",
    "+ conda install anaconda-client\n",
    "+ conda update anaconda\n",
    "+ pip install azureml-sdk[notebooks,automl]\n",
    "+ pip install azureml-dataprep[pandas]\n",
    "+ conda update conda\n",
    "\n",
    "**Note: If you need to upgrade the azureml components, uninstall the old version first before install the new ones.**\n",
    "\n",
    "OR you can use a [free Microsoft Azure Notebooks](https://notebooks.azure.com/) to run this notebook if you don't have Anaconda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Azure Machine Learning SDK for Python \n",
    "\n",
    "This step is to check that you have installed Azure Machine Learning SDK for Python.\n",
    "\n",
    "**Note: if you encounter ModuleNotFoundError, try uninstall all the azureml components first then re-install them again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "check version"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.24.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "# check core SDK version number (need Python 3.6 kernel if you run this in Microsoft Azure Notebooks)\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect Azure Machine Learning Workspace\n",
    "\n",
    "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file **config.json** and loads the details into an object named `workspace`.\n",
    "\n",
    "If you see this message:\n",
    "\"Performing interactive authentication. Please follow the instructions on the terminal.\n",
    "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code &lt;token\\&gt; to authenticate.\"\n",
    "    \n",
    "Click on the link and use the &lt;token\\&gt; given to authenticate. After authenticated, run this script again to get load the Workspace.&lt;/token\\&gt;&lt;/token\\&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "load workspace"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csidmlws\tsoutheastasia\tcmt-202011001\tsoutheastasia\n"
     ]
    }
   ],
   "source": [
    "# Load workspace configuration from the config.json file in the current folder.\n",
    "from azureml.core import Workspace\n",
    "workspace = Workspace.from_config()\n",
    "print(workspace.name, workspace.location, workspace.resource_group, workspace.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Experiment\n",
    "\n",
    "An Experiment tracks the runs in your workspace. A workspace can have muliple experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "create experiment"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'predict-emailservice-xgboost'\n",
    "exp = Experiment(workspace=workspace, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data\n",
    "\n",
    "This example read api data from Azure Search Service. It requires a api_config.json that has Azure Search Service credentials. A python script **Azure_search_client.py** which has helper functions which help to extract data from Azure Search Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_search_client import azure_search_client as azs_client \n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent\n",
    "import datetime\n",
    "from itertools import chain\n",
    "import random\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *get_search_results* \n",
    "\n",
    "This function sends the query into azure search service and produce the results in json format.\n",
    "\n",
    "read in 2 inputs : service and query. \n",
    "1. service :class, is a class created using azure_search_client.py \n",
    "2. query :string, what we wish to send to the azure search service.\n",
    "\n",
    "output: json dictionary\n",
    "\n",
    "### *retrieve_from_search* \n",
    "\n",
    "This function calls *get_search_results* and flatten the json output into pandas dataframe. It then creates random ratings and create session id and query column.\n",
    "\n",
    "read in 3 inputs : query, sessionid, azs_service\n",
    "1. service :class, is a class created using azure_search_client.py \n",
    "2. query :string, what we wish to send to the azure search service.\n",
    "3. sessionid :int\n",
    "\n",
    "output: pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(service, query):\n",
    "    search_request_body = {\n",
    "        \"search\": query,\n",
    "        \"featuresMode\": \"enabled\",\n",
    "        \"scoringStatistics\": \"global\",\n",
    "        \"count\": \"true\"\n",
    "    }\n",
    "    return service.search(search_request_body)\n",
    "\n",
    "def retrieve_from_search(query, sessionid, azs_service):\n",
    "    \n",
    "    ## Call the api service to retrieve json format data\n",
    "    json_search_results = get_search_results(azs_service, query)\n",
    "    \n",
    "    ## Flatten the json format data into pandas dataframe\n",
    "    search_results = json_normalize(json_search_results).fillna(0)\n",
    "    search_results = search_results.fillna(0).sort_values(['@search.score'], ascending=False)\n",
    "    search_results['query'] = query.lower()\n",
    "    search_results['sessionid'] = sessionid\n",
    "    print('{} rows for query : {}'.format(search_results.shape[0], query))\n",
    "    \n",
    "    #Producing random ratings which can be remove during production stage\n",
    "    rows = search_results.shape[0]\n",
    "    first = random.randint(1, rows)\n",
    "    second = random.randint(1, rows-first) if first < rows else 0\n",
    "    third = rows-first-second\n",
    "    sequence = [5]* first + [3]* second+[1]* third\n",
    "    random.shuffle(sequence)\n",
    "    search_results['rating'] = sequence\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code connects to the api service using the api_config json that we created. You may follow Guide for Azure Search Service.pdf to understand the location in retrieving the credentials required.\n",
    "\n",
    "The api_config.json looks like this:\n",
    "\n",
    "\n",
    "{\"service_name\": \"xxxxx\", \n",
    "    \"endpoint\": \"xxxxx\", \n",
    "    \"api_version\": \"2020-06-30-preview\", \n",
    "    \"api_key\": \"xxxxx\", \n",
    "    \"index_name\": \"xxxxx\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure_search_client.azure_search_client at 0x7f69d0661fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azs_service = azs_client.from_json('api_config.json')\n",
    "azs_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates hardcoded queries that would be send to the search service using the function <i>retrieve_from_search</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 rows for query : thank you\n",
      "3 rows for query : clarify\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@search.score</th>\n",
       "      <th>AzureSearch_DocumentKey</th>\n",
       "      <th>@search.features.BODY_Q.uniqueTokenMatches</th>\n",
       "      <th>@search.features.BODY_Q.similarityScore</th>\n",
       "      <th>@search.features.BODY_Q.termFrequency</th>\n",
       "      <th>@search.features.BODY_R.uniqueTokenMatches</th>\n",
       "      <th>@search.features.BODY_R.similarityScore</th>\n",
       "      <th>@search.features.BODY_R.termFrequency</th>\n",
       "      <th>query</th>\n",
       "      <th>sessionid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.936771</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.892284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.564289</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.811404</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.246215</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.208126</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.246215</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.208126</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.962676</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.962676</td>\n",
       "      <td>4.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.804916</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.849617</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>12.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.551757</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.551757</td>\n",
       "      <td>8.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.457604</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.416613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>10.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.355074</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.355074</td>\n",
       "      <td>7.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.105296</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.064417</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.906592</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>7.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.799633</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046748</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.634679</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045831</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.045831</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045831</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.044488</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.044256</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044256</td>\n",
       "      <td>9.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.042261</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>7.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.040879</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.038628</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038628</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.035841</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035841</td>\n",
       "      <td>2.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.012895</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.012895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.417329</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.417329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.417329</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.417329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    @search.score                            AzureSearch_DocumentKey  \\\n",
       "0        2.936771  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "1        2.564289  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "2        2.246215  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "3        2.246215  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "4        1.962676  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "5        1.804916  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "6        1.551757  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "7        1.457604  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "8        1.355074  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "9        1.105296  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "10       0.906592  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "11       0.799633  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "12       0.634679  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "13       0.045831  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "14       0.044488  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "15       0.044256  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "16       0.042261  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "17       0.040879  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "18       0.038628  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "19       0.035841  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "0        2.012895  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "1        1.417329  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "2        1.417329  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "\n",
       "    @search.features.BODY_Q.uniqueTokenMatches  \\\n",
       "0                                          2.0   \n",
       "1                                          1.0   \n",
       "2                                          2.0   \n",
       "3                                          2.0   \n",
       "4                                          0.0   \n",
       "5                                          1.0   \n",
       "6                                          0.0   \n",
       "7                                          2.0   \n",
       "8                                          0.0   \n",
       "9                                          2.0   \n",
       "10                                         1.0   \n",
       "11                                         1.0   \n",
       "12                                         1.0   \n",
       "13                                         0.0   \n",
       "14                                         0.0   \n",
       "15                                         0.0   \n",
       "16                                         0.0   \n",
       "17                                         0.0   \n",
       "18                                         0.0   \n",
       "19                                         0.0   \n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "\n",
       "    @search.features.BODY_Q.similarityScore  \\\n",
       "0                                  2.892284   \n",
       "1                                  0.752885   \n",
       "2                                  2.208126   \n",
       "3                                  2.208126   \n",
       "4                                  0.000000   \n",
       "5                                  0.849617   \n",
       "6                                  0.000000   \n",
       "7                                  1.416613   \n",
       "8                                  0.000000   \n",
       "9                                  1.064417   \n",
       "10                                 0.864331   \n",
       "11                                 0.752885   \n",
       "12                                 0.588848   \n",
       "13                                 0.000000   \n",
       "14                                 0.000000   \n",
       "15                                 0.000000   \n",
       "16                                 0.000000   \n",
       "17                                 0.000000   \n",
       "18                                 0.000000   \n",
       "19                                 0.000000   \n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "\n",
       "    @search.features.BODY_Q.termFrequency  \\\n",
       "0                                     5.0   \n",
       "1                                     1.0   \n",
       "2                                     2.0   \n",
       "3                                     2.0   \n",
       "4                                     0.0   \n",
       "5                                     2.0   \n",
       "6                                     0.0   \n",
       "7                                     2.0   \n",
       "8                                     0.0   \n",
       "9                                     2.0   \n",
       "10                                    1.0   \n",
       "11                                    1.0   \n",
       "12                                    1.0   \n",
       "13                                    0.0   \n",
       "14                                    0.0   \n",
       "15                                    0.0   \n",
       "16                                    0.0   \n",
       "17                                    0.0   \n",
       "18                                    0.0   \n",
       "19                                    0.0   \n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "\n",
       "    @search.features.BODY_R.uniqueTokenMatches  \\\n",
       "0                                          1.0   \n",
       "1                                          2.0   \n",
       "2                                          1.0   \n",
       "3                                          1.0   \n",
       "4                                          2.0   \n",
       "5                                          2.0   \n",
       "6                                          2.0   \n",
       "7                                          1.0   \n",
       "8                                          2.0   \n",
       "9                                          1.0   \n",
       "10                                         1.0   \n",
       "11                                         1.0   \n",
       "12                                         1.0   \n",
       "13                                         1.0   \n",
       "14                                         1.0   \n",
       "15                                         1.0   \n",
       "16                                         1.0   \n",
       "17                                         1.0   \n",
       "18                                         1.0   \n",
       "19                                         1.0   \n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "2                                          1.0   \n",
       "\n",
       "    @search.features.BODY_R.similarityScore  \\\n",
       "0                                  0.044488   \n",
       "1                                  1.811404   \n",
       "2                                  0.038090   \n",
       "3                                  0.038090   \n",
       "4                                  1.962676   \n",
       "5                                  0.955299   \n",
       "6                                  1.551757   \n",
       "7                                  0.040991   \n",
       "8                                  1.355074   \n",
       "9                                  0.040879   \n",
       "10                                 0.042261   \n",
       "11                                 0.046748   \n",
       "12                                 0.045831   \n",
       "13                                 0.045831   \n",
       "14                                 0.044488   \n",
       "15                                 0.044256   \n",
       "16                                 0.042261   \n",
       "17                                 0.040879   \n",
       "18                                 0.038628   \n",
       "19                                 0.035841   \n",
       "0                                  2.012895   \n",
       "1                                  1.417329   \n",
       "2                                  1.417329   \n",
       "\n",
       "    @search.features.BODY_R.termFrequency      query  sessionid  rating  \n",
       "0                                     5.0  thank you          1       5  \n",
       "1                                     6.0  thank you          1       5  \n",
       "2                                     2.0  thank you          1       5  \n",
       "3                                     2.0  thank you          1       5  \n",
       "4                                     4.0  thank you          1       5  \n",
       "5                                    12.0  thank you          1       5  \n",
       "6                                     8.0  thank you          1       5  \n",
       "7                                    10.0  thank you          1       5  \n",
       "8                                     7.0  thank you          1       5  \n",
       "9                                     6.0  thank you          1       5  \n",
       "10                                    7.0  thank you          1       5  \n",
       "11                                    5.0  thank you          1       5  \n",
       "12                                    5.0  thank you          1       5  \n",
       "13                                    5.0  thank you          1       5  \n",
       "14                                    5.0  thank you          1       5  \n",
       "15                                    9.0  thank you          1       5  \n",
       "16                                    7.0  thank you          1       5  \n",
       "17                                    6.0  thank you          1       3  \n",
       "18                                    6.0  thank you          1       5  \n",
       "19                                    2.0  thank you          1       5  \n",
       "0                                     1.0    clarify          2       5  \n",
       "1                                     1.0    clarify          2       1  \n",
       "2                                     1.0    clarify          2       3  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the necessary queries to create dataset\n",
    "query_input = ['thank you', 'clarify']\n",
    "\n",
    "query_dataset = pd.DataFrame()\n",
    "sessionid =1\n",
    "for query in query_input:\n",
    "    query_dataset = pd.concat([query_dataset, retrieve_from_search(query, sessionid, azs_service)])\n",
    "    sessionid+=1\n",
    "    \n",
    "query_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataset into blob storage \n",
    "We can use code to save our dataframe query_dataset into a file and push this file into our datastore. As such, other members just require the file directory in the datastore to read this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading data/query_dataset.csv\n",
      "Uploaded data/query_dataset.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "os.makedirs('data', exist_ok=True)\n",
    "local_path = 'data/query_dataset.csv'\n",
    "query_dataset.to_csv(local_path)\n",
    "\n",
    "# get the datastore to upload prepared data\n",
    "datastore = workspace.get_default_datastore()\n",
    "\n",
    "# upload the local file from src_dir to the target_path in datastore\n",
    "datastore.upload(src_dir='data', target_path='data', overwrite=True)\n",
    "\n",
    "# reading the dataset referencing from datastore, \n",
    "# use .from_delimited_files as we are reading from csv\n",
    "reading_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data/query_dataset.csv'))])\n",
    "\n",
    "query_dataset = reading_dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To register the file as a dataset in AzureML workspace, we have ensure that our dataframe is a Dataset object\n",
    "The code __Dataset.Tabular.from_delimited_files__ creates a Dataset Object. We require our pandas dataframe to be a Dataset Object in order to register it in our AzureML Wirkspace. To convert Dataset Object to pandas dataframe, we just need to run __reading_dataset.to_pandas_dataframe()__\n",
    "\n",
    "+ create_new_version = True to allow updates to the current registered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "## This code has been run above to read as a dataset object from file name in datastore\n",
    "# reading_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data/query_dataset.csv'))])\n",
    "reading_dataset.register(workspace=workspace, name='query_dataset_tabular',create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To ensure that the dataset registered in the workspace is the same as our query_dataset, we can read the dataset from our created Dataset object in our workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@search.score</th>\n",
       "      <th>AzureSearch_DocumentKey</th>\n",
       "      <th>@search.features.BODY_Q.uniqueTokenMatches</th>\n",
       "      <th>@search.features.BODY_Q.similarityScore</th>\n",
       "      <th>@search.features.BODY_Q.termFrequency</th>\n",
       "      <th>@search.features.BODY_R.uniqueTokenMatches</th>\n",
       "      <th>@search.features.BODY_R.similarityScore</th>\n",
       "      <th>@search.features.BODY_R.termFrequency</th>\n",
       "      <th>query</th>\n",
       "      <th>sessionid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.936771</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.892284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.564289</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.811404</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.246215</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.208126</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.246215</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.208126</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.962676</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.962676</td>\n",
       "      <td>4.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.804916</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.849617</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>12.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.551757</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.551757</td>\n",
       "      <td>8.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.457604</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.416613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>10.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.355074</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.355074</td>\n",
       "      <td>7.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.105296</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.064417</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.906592</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>7.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.799633</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.046748</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.634679</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045831</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.045831</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045831</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.044488</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.044256</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044256</td>\n",
       "      <td>9.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.042261</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042261</td>\n",
       "      <td>7.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.040879</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.038628</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038628</td>\n",
       "      <td>6.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.035841</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035841</td>\n",
       "      <td>2.0</td>\n",
       "      <td>thank you</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.012895</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.012895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.417329</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.417329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.417329</td>\n",
       "      <td>aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.417329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarify</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    @search.score                            AzureSearch_DocumentKey  \\\n",
       "0        2.936771  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "1        2.564289  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "2        2.246215  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "3        2.246215  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "4        1.962676  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "5        1.804916  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "6        1.551757  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "7        1.457604  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "8        1.355074  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "9        1.105296  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "10       0.906592  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "11       0.799633  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "12       0.634679  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "13       0.045831  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "14       0.044488  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "15       0.044256  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "16       0.042261  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "17       0.040879  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "18       0.038628  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "19       0.035841  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "0        2.012895  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "1        1.417329  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "2        1.417329  aHR0cHM6Ly9jc2lkZW1haWxkYXRhLmJsb2IuY29yZS53aW...   \n",
       "\n",
       "    @search.features.BODY_Q.uniqueTokenMatches  \\\n",
       "0                                          2.0   \n",
       "1                                          1.0   \n",
       "2                                          2.0   \n",
       "3                                          2.0   \n",
       "4                                          0.0   \n",
       "5                                          1.0   \n",
       "6                                          0.0   \n",
       "7                                          2.0   \n",
       "8                                          0.0   \n",
       "9                                          2.0   \n",
       "10                                         1.0   \n",
       "11                                         1.0   \n",
       "12                                         1.0   \n",
       "13                                         0.0   \n",
       "14                                         0.0   \n",
       "15                                         0.0   \n",
       "16                                         0.0   \n",
       "17                                         0.0   \n",
       "18                                         0.0   \n",
       "19                                         0.0   \n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "\n",
       "    @search.features.BODY_Q.similarityScore  \\\n",
       "0                                  2.892284   \n",
       "1                                  0.752885   \n",
       "2                                  2.208126   \n",
       "3                                  2.208126   \n",
       "4                                  0.000000   \n",
       "5                                  0.849617   \n",
       "6                                  0.000000   \n",
       "7                                  1.416613   \n",
       "8                                  0.000000   \n",
       "9                                  1.064417   \n",
       "10                                 0.864331   \n",
       "11                                 0.752885   \n",
       "12                                 0.588848   \n",
       "13                                 0.000000   \n",
       "14                                 0.000000   \n",
       "15                                 0.000000   \n",
       "16                                 0.000000   \n",
       "17                                 0.000000   \n",
       "18                                 0.000000   \n",
       "19                                 0.000000   \n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "\n",
       "    @search.features.BODY_Q.termFrequency  \\\n",
       "0                                     5.0   \n",
       "1                                     1.0   \n",
       "2                                     2.0   \n",
       "3                                     2.0   \n",
       "4                                     0.0   \n",
       "5                                     2.0   \n",
       "6                                     0.0   \n",
       "7                                     2.0   \n",
       "8                                     0.0   \n",
       "9                                     2.0   \n",
       "10                                    1.0   \n",
       "11                                    1.0   \n",
       "12                                    1.0   \n",
       "13                                    0.0   \n",
       "14                                    0.0   \n",
       "15                                    0.0   \n",
       "16                                    0.0   \n",
       "17                                    0.0   \n",
       "18                                    0.0   \n",
       "19                                    0.0   \n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "\n",
       "    @search.features.BODY_R.uniqueTokenMatches  \\\n",
       "0                                          1.0   \n",
       "1                                          2.0   \n",
       "2                                          1.0   \n",
       "3                                          1.0   \n",
       "4                                          2.0   \n",
       "5                                          2.0   \n",
       "6                                          2.0   \n",
       "7                                          1.0   \n",
       "8                                          2.0   \n",
       "9                                          1.0   \n",
       "10                                         1.0   \n",
       "11                                         1.0   \n",
       "12                                         1.0   \n",
       "13                                         1.0   \n",
       "14                                         1.0   \n",
       "15                                         1.0   \n",
       "16                                         1.0   \n",
       "17                                         1.0   \n",
       "18                                         1.0   \n",
       "19                                         1.0   \n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "2                                          1.0   \n",
       "\n",
       "    @search.features.BODY_R.similarityScore  \\\n",
       "0                                  0.044488   \n",
       "1                                  1.811404   \n",
       "2                                  0.038090   \n",
       "3                                  0.038090   \n",
       "4                                  1.962676   \n",
       "5                                  0.955299   \n",
       "6                                  1.551757   \n",
       "7                                  0.040991   \n",
       "8                                  1.355074   \n",
       "9                                  0.040879   \n",
       "10                                 0.042261   \n",
       "11                                 0.046748   \n",
       "12                                 0.045831   \n",
       "13                                 0.045831   \n",
       "14                                 0.044488   \n",
       "15                                 0.044256   \n",
       "16                                 0.042261   \n",
       "17                                 0.040879   \n",
       "18                                 0.038628   \n",
       "19                                 0.035841   \n",
       "0                                  2.012895   \n",
       "1                                  1.417329   \n",
       "2                                  1.417329   \n",
       "\n",
       "    @search.features.BODY_R.termFrequency      query  sessionid  rating  \n",
       "0                                     5.0  thank you          1       5  \n",
       "1                                     6.0  thank you          1       5  \n",
       "2                                     2.0  thank you          1       5  \n",
       "3                                     2.0  thank you          1       5  \n",
       "4                                     4.0  thank you          1       5  \n",
       "5                                    12.0  thank you          1       5  \n",
       "6                                     8.0  thank you          1       5  \n",
       "7                                    10.0  thank you          1       5  \n",
       "8                                     7.0  thank you          1       5  \n",
       "9                                     6.0  thank you          1       5  \n",
       "10                                    7.0  thank you          1       5  \n",
       "11                                    5.0  thank you          1       5  \n",
       "12                                    5.0  thank you          1       5  \n",
       "13                                    5.0  thank you          1       5  \n",
       "14                                    5.0  thank you          1       5  \n",
       "15                                    9.0  thank you          1       5  \n",
       "16                                    7.0  thank you          1       5  \n",
       "17                                    6.0  thank you          1       3  \n",
       "18                                    6.0  thank you          1       5  \n",
       "19                                    2.0  thank you          1       5  \n",
       "0                                     1.0    clarify          2       5  \n",
       "1                                     1.0    clarify          2       1  \n",
       "2                                     1.0    clarify          2       3  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='query_dataset_tabular')\n",
    "query_dataset = dataset.to_pandas_dataframe()\n",
    "\n",
    "query_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to create a simple XGBRanker model from xgboost package to run prediction on our query_dataset. The scores are how the outputs of each group are in comparision with each other. The higher the score would be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44844714, -0.44844714, -0.44844714, -0.44844714, -0.44844714,\n",
       "       -0.44844714, -0.44844714, -0.44844714, -0.44844714, -0.44844714,\n",
       "       -0.44844714, -0.44844714, -0.44844714, -0.44844714, -0.44844714,\n",
       "       -0.44844714, -0.44844714, -0.44844714, -0.44844714, -0.44844714,\n",
       "        1.4972795 , -0.44844714, -0.44844714], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = query_dataset, query_dataset.rating\n",
    "\n",
    "#### Query labels for each document in our dataset.\n",
    "query_ids = X['sessionid'].to_numpy()\n",
    "\n",
    "params = {'objective': 'rank:ndcg', 'learning_rate': 0.5\n",
    "          ,'min_child_weight': 0.1\n",
    "#           , 'reg_alpha': 0.5\n",
    "          ,'max_depth': 10, 'n_estimators': 200\n",
    "         }\n",
    "\n",
    "ranker = xgb.XGBRanker(**params)\n",
    "\n",
    "# Choose only columns that are numeric\n",
    "ranker.fit(X.drop(columns=['query','rating', 'sessionid', 'AzureSearch_DocumentKey', 'keyphrases'], axis=1),\n",
    "           y, np.unique(query_ids, return_counts=True)[1],\n",
    "           eval_metric='ndcg',\n",
    "           verbose=False)\n",
    "\n",
    "xgb_scores = ranker.predict(X.drop(columns=['query','rating', 'sessionid',\n",
    "                                            'AzureSearch_DocumentKey', 'keyphrases'], axis=1))\n",
    "xgb_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_score = pd.DataFrame(xgb_scores)\n",
    "output_score.columns=['score']\n",
    "output_score_sorted = output_score.sort_values('score', ascending = True).reset_index()\n",
    "num_rows = output_score_sorted.shape[0]\n",
    "rate_3 = int(num_rows*0.7)\n",
    "rate_1 = int(num_rows*0.2)\n",
    "output_score_sorted['pred_rating'] = 5\n",
    "output_score_sorted.loc[0: rate_1, 'pred_rating'] = 1\n",
    "output_score_sorted.loc[rate_1: rate_3, 'pred_rating'] = 3\n",
    "query_dataset['index'] = query_dataset .index\n",
    "check_acc = query_dataset.merge(output_score_sorted, on = ['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a self defined score metric to calculate the accuracy of the model\n",
    "+ If both pred_rating and rating are the same, score of 1 is awarded\n",
    "+ If both pred_rating and rating are not the same, case when\n",
    "  + pred_rating is 5, rating is 1, score of 0 is awarded, vice versa\n",
    "  + pred_rating is 5, rating is 3, score of 0.5 is awarded, vice versa\n",
    "  + pred_rating is 3, rating is 1, score of 0 is awarded.\n",
    "  + pred_rating is 1, rating is 3, score of 0.5 is awarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Accuracy is 0.51\n",
      "Accuracy is 0.69\n"
     ]
    }
   ],
   "source": [
    "def score_metric(x):\n",
    "    \n",
    "    if (x.pred_rating == 5 and x.rating ==1) or (x.pred_rating == 1 and x.rating ==5):\n",
    "        return 0\n",
    "    \n",
    "    if (x.pred_rating == 5 and x.rating == 3) or (x.pred_rating == 3 and x.rating == 5):\n",
    "        return 0.5\n",
    "    \n",
    "    if x.pred_rating == 1 and x.rating == 3:\n",
    "        return 0.5\n",
    "    \n",
    "    if x.pred_rating == 3 and x.rating == 1:\n",
    "        return 0\n",
    "    \n",
    "    if (x.pred_rating == x.rating):\n",
    "        return 1\n",
    "\n",
    "print('Exact Accuracy is', round((check_acc['pred_rating']==check_acc['rating']).sum()/check_acc.shape[0], 2))\n",
    "print('Accuracy is', round(sum(check_acc.apply(lambda x: score_metric(x), axis = 1))/check_acc.shape[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "For this task, submit a job to train model in your local machine. To submit a job you:\n",
    "\n",
    "* Create training scripts\n",
    "* Create training environment\n",
    "* Submit a run\n",
    "\n",
    "The training results will be stored in your Azure ML workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Create training scripts\n",
    "\n",
    "Create training scripts in the directory you just created. Notice how the script saves the model:\n",
    "    \n",
    "+ The training script saves your model into a directory named outputs. <br>\n",
    "`joblib.dump(value=clf, filename='outputs/predict-emailservice-xgboostmodel.pkl')`<br>\n",
    "Anything written in this directory is automatically uploaded into your workspace. You'll access your model from this directory later in the tutorial. <br>\n",
    " <br>\n",
    "+ The first script (train_email.py) reads in the credentials to generate our training dataset. The second script follows the same model building code that we use to build and train our model. <br>\n",
    " <br>\n",
    "+ run.log(xxx, yyy) will create a print statement when we submit a run. XXX will be the name and YYY will be the value. It is similar to a log file.\n",
    "\n",
    "[Run class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py)\n",
    "\n",
    "[Joblib](https://joblib.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_email_xgboost.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_email_xgboost.py\n",
    "\n",
    "# import argparse\n",
    "import os\n",
    "from azureml.core import Run\n",
    "from predict_emailservice_xgboost import generate_model\n",
    "from joblib import dump\n",
    "from azure_search_client import azure_search_client as azs_client \n",
    "import random\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "# Connecting to the api service\n",
    "azs_service = azs_client.from_json('api_config.json')\n",
    "run.log('Connecting to api service', azs_service)\n",
    "\n",
    "# Generate model\n",
    "xgb_ranker = generate_model(azs_service, run)\n",
    "\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "dump(value=xgb_ranker, filename='outputs/predict-emailservice-xgboostmodel.pkl')\n",
    "run.log('End of run','Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict_emailservice_xgboost.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_emailservice_xgboost.py\n",
    "\n",
    "from azureml.core import Run\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent\n",
    "import datetime\n",
    "from itertools import chain\n",
    "import random\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_search_results(service, query):\n",
    "    search_request_body = {\n",
    "        \"search\": query,\n",
    "        \"featuresMode\": \"enabled\",\n",
    "        \"scoringStatistics\": \"global\",\n",
    "        \"count\": \"true\"\n",
    "    }\n",
    "    \n",
    "    return service.search(search_request_body)\n",
    "\n",
    "def retrieve_from_search(query, sessionid, azs_service):\n",
    "    \n",
    "    ## Call the api service to retrieve json format data\n",
    "    json_search_results = get_search_results(azs_service, query)\n",
    "    \n",
    "    ## Flatten the json format data into pandas dataframe\n",
    "    search_results = json_normalize(json_search_results).fillna(0)\n",
    "    search_results = search_results.fillna(0).sort_values(['@search.score'], ascending=False)\n",
    "    search_results['query'] = query.lower()\n",
    "    search_results['sessionid'] = sessionid\n",
    "    print('{} rows for query : {}'.format(search_results.shape[0], query))\n",
    "    \n",
    "    #Producing random ratings which can be remove during production stage\n",
    "    rows = search_results.shape[0]\n",
    "    first = random.randint(1, rows)\n",
    "    second = random.randint(1, rows-first) if first < rows else 0\n",
    "    third = rows-first-second\n",
    "    sequence = [5]* first + [3]* second+[1]* third\n",
    "    random.shuffle(sequence)\n",
    "    search_results['rating'] = sequence\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "\n",
    "def score_metric(x):\n",
    "    \n",
    "    if (x.pred_rating == 5 and x.rating ==1) or (x.pred_rating == 1 and x.rating ==5):\n",
    "        return 0\n",
    "    \n",
    "    if (x.pred_rating == 5 and x.rating == 3) or (x.pred_rating == 3 and x.rating == 5):\n",
    "        return 0.5\n",
    "    \n",
    "    if x.pred_rating == 1 and x.rating == 3:\n",
    "        return 0.5\n",
    "    \n",
    "    if x.pred_rating == 3 and x.rating == 1:\n",
    "        return 0\n",
    "    \n",
    "    if (x.pred_rating == x.rating):\n",
    "        return 1\n",
    "    \n",
    "def generate_model(azs_service, run):\n",
    "    \n",
    "    # Create the necessary queries to create dataset\n",
    "    query_input = ['how to do child relief', 'income tax ', 'transfer account', 'claim',\n",
    "                   'whats child relief', 'do claims', 'PTR claim', 'how to do Course Fees Relief', \n",
    "                   'reduce tax', 'tax filing', 'reduce personal relief', 'duplicate relief', \n",
    "                   'state unavailability', 'university relief', 'auto-inclusion scheme (AIS)', 'e-Service availablility', \n",
    "                   'child relief', 'tax claim', 'relief', 'income']\n",
    "\n",
    "    query_dataset = pd.DataFrame()\n",
    "    sessionid =1\n",
    "    for query in query_input:\n",
    "        query_dataset = pd.concat([query_dataset, retrieve_from_search(query, sessionid, azs_service)])\n",
    "        sessionid+=1\n",
    "\n",
    "    query_dataset = query_dataset.fillna(0).reset_index(drop =True)\n",
    "\n",
    "    X, y = query_dataset, query_dataset.rating\n",
    "\n",
    "    # Query labels for each document in our dataset.\n",
    "    query_ids = X['sessionid'].to_numpy()\n",
    "\n",
    "\n",
    "    params = {'objective': 'rank:ndcg', 'learning_rate': 0.5\n",
    "          ,'min_child_weight': 0.1\n",
    "#           , 'reg_alpha': 0.5\n",
    "          ,'max_depth': 10, 'n_estimators': 200\n",
    "         }\n",
    "\n",
    "    xgb_ranker = xgb.XGBRanker(**params)\n",
    "    run.log('Setting up xgb params', params)\n",
    "\n",
    "    xgb_ranker.fit(X.drop(columns=['query','rating', 'sessionid', 'AzureSearch_DocumentKey', 'keyphrases'], axis=1)\n",
    "                   , y, np.unique(query_ids, return_counts=True)[1],\n",
    "               eval_metric='ndcg',\n",
    "               verbose=False)\n",
    "\n",
    "    \n",
    "    xgb_scores = xgb_ranker.predict(X.drop(columns=['query','rating', 'sessionid', 'AzureSearch_DocumentKey', 'keyphrases'], axis=1))\n",
    "\n",
    "    # Create the output dataset and also the accuracy\n",
    "    output_score = pd.DataFrame(xgb_scores)\n",
    "    output_score.columns=['score']\n",
    "    output_score_sorted = output_score.sort_values('score', ascending = True).reset_index()\n",
    "    num_rows = output_score_sorted.shape[0]\n",
    "    rate_3 = int(num_rows*0.7)\n",
    "    rate_1 = int(num_rows*0.2)\n",
    "    output_score_sorted['pred_rating'] = 5\n",
    "    output_score_sorted.loc[0: rate_1, 'pred_rating'] = 1\n",
    "    output_score_sorted.loc[rate_1: rate_3, 'pred_rating'] = 3\n",
    "    \n",
    "    run.log('Predicted value counts', output_score_sorted.pred_rating.value_counts())\n",
    "        \n",
    "    query_dataset['index'] = query_dataset .index\n",
    "    check_acc = query_dataset.merge(output_score_sorted, on = ['index'])\n",
    "    \n",
    "    run.log('Exact Accuracy is', round((check_acc['pred_rating']==check_acc['rating']).sum()/check_acc.shape[0], 2))\n",
    "    run.log('Accuracy is', round(sum(check_acc.apply(lambda x: score_metric(x), axis = 1))/check_acc.shape[0], 2))\n",
    "    \n",
    "    return xgb_ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Create training environment in local machine\n",
    "\n",
    "The steps here is to create a local training environment, such as to leverage on the Anaconda installed on local machine. However, you can also run this \"locally\" in the Microsoft Azure Notebooks.\n",
    "\n",
    "Details are provided at https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#local\n",
    "    \n",
    "[What are Azure Machine Learning environments?](https://docs.microsoft.com/en-us/azure/machine-learning/concept-environments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a user-managed environment\n",
    "By default, Azure Machine Learning service will build a Conda environment with dependencies you specified, and will execute the run in that environment instead of using any Python libraries that you installed on the base image.\n",
    "A later example in this example will demonstrate the use of Environment when training the model on Azure. \n",
    "\n",
    "In some situations, your custom base image may already contain a Python environment with packages that you want to use.\n",
    "\n",
    "When using a user-managed environment for local training, you are responsible for ensuring that all the necessary packages are available in the Python environment you choose to run the script in.\n",
    "\n",
    "+ Create and attach: There's no need to create or attach a compute target to use your local computer as the training environment.\n",
    "+ Configure: When you use your local computer as a compute target, the training code is run in your development environment. If that environment already has the Python packages you need, use the user-managed environment.\n",
    "\n",
    "To use your own installed packages, set the parameter Environment.python.user_managed_dependencies = True. Ensure that the base image contains a Python interpreter, and has the packages your training script needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a 'user-managed environment' environment.\n",
    "user_managed_env = Environment(\"user-managed-env-xgboost\")\n",
    "\n",
    "user_managed_env.python.user_managed_dependencies = True\n",
    "\n",
    "# You can choose a specific Python environment by pointing to a Python path \n",
    "#user_managed_env.python.interpreter_path = '/home/johndoe/miniconda3/envs/myenv/bin/python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ScriptRunConfig\n",
    "\n",
    "Whatever the way you manage your environment, you need to use the ScriptRunConfig class. ScriptRunConfig identifies the training script to run in the experiment and the environment in which to run it. \n",
    "\n",
    "ScriptRunConfig includes\n",
    "+ source_directory: The source directory that contains your training script\n",
    "+ script: Identify the training script\n",
    "+ run_config: The run configuration, which in turn defines where the training will occur\n",
    "\n",
    "Note: ScriptRunConfig doesn't allow you to pass dataset to the training script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(source_directory= directory, script='train_email_xgboost.py')\n",
    "src.run_config.environment = user_managed_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submit a run\n",
    "\n",
    "After you create a run configuration, you use it to run your experiment. An experiment is a logical container in an Azure ML Workspace. It contains a series of trials called Runs. As such, it hosts run records such as run metrics, logs, and other output artifacts from your experiments.\n",
    "\n",
    "The code pattern to submit a training run is the same for all types of compute targets:\n",
    "+ Create an experiment to run.\n",
    "+ Submit the run.\n",
    "+ Wait for the run to complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>predict-emailservice-xgboost</td><td>predict-emailservice-xgboost_1618551593_b1da1b58</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/predict-emailservice-xgboost/runs/predict-emailservice-xgboost_1618551593_b1da1b58?wsid=/subscriptions/ebe8d9fa-67d0-4af1-bce2-4a5b07e50a42/resourcegroups/cmt-202011001/workspaces/csidmlws\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: predict-emailservice-xgboost,\n",
       "Id: predict-emailservice-xgboost_1618551593_b1da1b58,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(src)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the run to complete\n",
    "\n",
    "After you submit the run, you can immediately execute this code to watch the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10 to 15 seconds until the job finishes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92c35235656497e98abee223e2054c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/predict-emailservice-xgboost/runs/predict-emailservice-xgboost_1618551593_b1da1b58?wsid=/subscriptions/ebe8d9fa-67d0-4af1-bce2-4a5b07e50a42/resourcegroups/cmt-202011001/workspaces/csidmlws\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"run_properties\": {\"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"created_utc\": \"2021-04-16T05:39:56.342475Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"fc3ece24-ba9a-4631-907f-c2d9b8c962ea\"}, \"tags\": {\"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"train_email_xgboost.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-04-16T05:40:14.123717Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://csidmlws4729607923.blob.core.windows.net/azureml/ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=wtvs8SNr%2FrczpUbzzEkCT23LC3%2FhN7od%2B3zJwTY3nCg%3D&st=2021-04-16T05%3A30%3A16Z&se=2021-04-16T13%3A40%3A16Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://csidmlws4729607923.blob.core.windows.net/azureml/ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=xlfqImIQF7N%2FJikFFd%2FvGe9bQAZv5TDXJU7p9eppwUc%3D&st=2021-04-16T05%3A30%3A16Z&se=2021-04-16T13%3A40%3A16Z&sp=r\", \"logs/azureml/4279_azureml.log\": \"https://csidmlws4729607923.blob.core.windows.net/azureml/ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/logs/azureml/4279_azureml.log?sv=2019-02-02&sr=b&sig=7tHIfXH2sJqDoApbj022o9UrDtbNl2OHw10%2Fo7rqV0I%3D&st=2021-04-16T05%3A30%3A10Z&se=2021-04-16T13%3A40%3A10Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/4279_azureml.log\"]], \"run_duration\": \"0:00:17\", \"run_number\": \"291\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Connecting to api service\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"categories\": [0], \"series\": [{\"data\": [\"<azure_search_client.azure_search_client object at 0x7fdbc03af2b0>\"]}]}, {\"name\": \"Setting up xgb params\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"categories\": [0], \"series\": [{\"data\": [\"{'objective': 'rank:ndcg', 'learning_rate': 0.5, 'min_child_weight': 0.1, 'max_depth': 10, 'n_estimators': 200}\"]}]}, {\"name\": \"Predicted value counts\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"categories\": [0], \"series\": [{\"data\": [\"3    142\\n5     84\\n1     56\\nName: pred_rating, dtype: int64\"]}]}, {\"name\": \"Exact Accuracy is\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"categories\": [0], \"series\": [{\"data\": [0.5]}]}, {\"name\": \"Accuracy is\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"categories\": [0], \"series\": [{\"data\": [0.67]}]}, {\"name\": \"End of run\", \"run_id\": \"predict-emailservice-xgboost_1618551593_b1da1b58\", \"categories\": [0], \"series\": [{\"data\": [\"Training completed\"]}]}], \"run_logs\": \"2021-04-16 05:40:00,326|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2021-04-16 05:40:00,327|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2021-04-16 05:40:00,397|azureml.history._tracking.PythonWorkingDirectory|DEBUG|PySpark found in environment.\\n2021-04-16 05:40:00,397|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-04-16 05:40:00,772|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2021-04-16 05:40:00,772|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2021-04-16 05:40:00,772|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2021-04-16 05:40:00,772|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2021-04-16 05:40:00,772|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7fdbe434e048> for run source hyperdrive\\n2021-04-16 05:40:01,092|azureml.core.run|DEBUG|Adding new factory <function AutoMLRun._from_run_dto at 0x7fdbe2acb048> for run source automl\\n2021-04-16 05:40:01,103|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7fdbe4013f28> for run source azureml.PipelineRun\\n2021-04-16 05:40:01,113|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7fdbe401d9d8> for run source azureml.ReusedStepRun\\n2021-04-16 05:40:01,122|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7fdbe401d950> for run source azureml.StepRun\\n2021-04-16 05:40:01,132|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fdbe45297b8> for run source azureml.scriptrun\\n2021-04-16 05:40:01,135|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-04-16 05:40:01,135|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-04-16 05:40:01,135|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-04-16 05:40:01,136|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-04-16 05:40:01,136|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-04-16 05:40:01,136|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-04-16 05:40:01,138|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-16 05:40:01,154|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-04-16 05:40:01,154|azureml.core.authentication|DEBUG|Time to expire 1814394.84539 seconds\\n2021-04-16 05:40:01,154|azureml.core.authentication|DEBUG|Time to expire 1814394.845222 seconds\\n2021-04-16 05:40:01,154|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-04-16 05:40:01,155|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-04-16 05:40:01,155|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,156|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,157|azureml.core.authentication|DEBUG|Time to expire 1814394.842681 seconds\\n2021-04-16 05:40:01,157|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-04-16 05:40:01,158|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,158|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,160|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,173|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,173|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,173|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,173|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,215|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-04-16 05:40:01,215|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-04-16 05:40:01,228|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,237|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,245|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-04-16 05:40:01,245|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,245|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-04-16 05:40:01,245|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,248|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:01,280|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-04-16 05:40:01,281|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-04-16 05:40:01,651|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:01,651|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'fc3ece24-ba9a-4631-907f-c2d9b8c962ea'}\\n2021-04-16 05:40:01,652|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-04-16 05:40:01,666|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:01,667|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'fc3ece24-ba9a-4631-907f-c2d9b8c962ea'}\\n2021-04-16 05:40:01,667|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-04-16 05:40:01,853|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:01,854|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'fc3ece24-ba9a-4631-907f-c2d9b8c962ea'}\\n2021-04-16 05:40:01,855|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-04-16 05:40:02,479|azureml|DEBUG|Installed with mlflow version 1.14.1.\\n2021-04-16 05:40:02,480|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2021-04-16 05:40:02,483|azureml.mlflow|DEBUG|Creating a tracking uri in southeastasia.experiments.azureml.net for workspace /subscriptions/ebe8d9fa-67d0-4af1-bce2-4a5b07e50a42/resourceGroups/cmt-202011001/providers/Microsoft.MachineLearningServices/workspaces/csidmlws\\n2021-04-16 05:40:02,483|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-04-16 05:40:02,483|azureml.mlflow._internal.model_registry|DEBUG|Initializing the AzureMLflowModelRegistry\\n2021-04-16 05:40:02,483|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2021-04-16 05:40:02,484|azureml.mlflow|DEBUG|Setting MLflow run id env var with predict-emailservice-xgboost_1618551593_b1da1b58\\n2021-04-16 05:40:02,484|azureml.mlflow|DEBUG|Setting Mlflow experiment with predict-emailservice-xgboost\\n2021-04-16 05:40:02,484|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2021-04-16 05:40:02,485|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2021-04-16 05:40:02,485|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2021-04-16 05:40:02,485|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_details with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/details\\n2021-04-16 05:40:03,236|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:03,239|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-04-16 05:40:03,239|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-04-16 05:40:03,839|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:03,840|azureml.WorkerPool|DEBUG|[START]\\n2021-04-16 05:40:03,840|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-04-16 05:40:03,840|azureml.RunStatusContext|DEBUG|[START]\\n2021-04-16 05:40:03,840|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-04-16 05:40:03,840|azureml.MetricsClient|DEBUG|[START]\\n2021-04-16 05:40:03,840|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-04-16 05:40:03,840|azureml.ContentUploader|DEBUG|[START]\\n2021-04-16 05:40:03,841|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2021-04-16 05:40:03,841|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2021-04-16 05:40:03,841|azureml.TrackFolders|DEBUG|[START]\\n2021-04-16 05:40:03,842|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-04-16 05:40:03,842|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-04-16 05:40:03,842|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58\\n2021-04-16 05:40:03,842|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-04-16 05:40:03,842|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58\\n2021-04-16 05:40:03,866|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-04-16 05:40:03,875|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-04-16 05:40:04,158|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-04-16 05:40:04,158|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-04-16 05:40:04,158|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-04-16 05:40:04,158|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,159|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southeastasia.experiments.azureml.net.\\n2021-04-16 05:40:04,233|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-04-16 05:40:04,234|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-16 05:40:04,234|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-04-16 05:40:05,140|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:05,179|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/logs/azureml/4279_azureml.log path: /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58/logs/azureml/4279_azureml.log\\n2021-04-16 05:40:05,181|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-04-16 05:40:05,188|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:05,188|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2021-04-16 05:40:05,235|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-04-16 05:40:05,235|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-04-16 05:40:05,236|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-04-16 05:40:05,237|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:05,239|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-04-16 05:40:05,239|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-04-16 05:40:05,239|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-04-16 05:40:05,239|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-04-16 05:40:05,239|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-04-16 05:40:05,237|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-04-16 05:40:05,245|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-04-16 05:40:05,246|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:05,246|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-04-16 05:40:05,250|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-04-16 05:40:05,251|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-04-16 05:40:05,499|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-04-16 05:40:05,502|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-04-16 05:40:05,502|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-04-16 05:40:05,502|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 0.005600690841674805 seconds.\\n\\n2021-04-16 05:40:05,502|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-04-16 05:40:06,235|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-04-16 05:40:06,235|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-04-16 05:40:06,236|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 5.\\n2021-04-16 05:40:06,236|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-04-16 05:40:06,236|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:06,236|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-04-16 05:40:06,236|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-04-16 05:40:06,236|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-04-16 05:40:06,236|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-04-16 05:40:06,236|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-04-16 05:40:06,237|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 5 values.\\n2021-04-16 05:40:06,237|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:06,237|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 1__log_batch_v2 to queue of approximate size: 1\\n2021-04-16 05:40:06,237|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-04-16 05:40:06,237|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-04-16 05:40:06,398|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:06,487|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-04-16 05:40:06,487|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-04-16 05:40:06,487|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-04-16 05:40:06,487|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 8.20159912109375e-05 seconds.\\n\\n2021-04-16 05:40:06,487|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58 to /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/predict-emailservice-xgboost_1618551593_b1da1b58\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-04-16 05:40:06,716|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2021-04-16 05:40:06,716|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-04-16 05:40:06,717|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2021-04-16 05:40:06,717|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/predict-emailservice-xgboostmodel.pkl\\n2021-04-16 05:40:06,717|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/predict-emailservice-xgboostmodel.pkl'] in dir ./outputs\\n2021-04-16 05:40:06,717|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2021-04-16 05:40:06,717|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2021-04-16 05:40:06,717|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-04-16 05:40:06,717|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-04-16 05:40:07,535|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-04-16 05:40:07,535|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-04-16 05:40:07,536|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:07,536|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2021-04-16 05:40:07,536|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-04-16 05:40:07,536|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2021-04-16 05:40:07,536|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2021-04-16 05:40:07,536|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2021-04-16 05:40:07,537|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2021-04-16 05:40:07,613|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/outputs/predict-emailservice-xgboostmodel.pkl with size 293223, file size 293223.\\n2021-04-16 05:40:07,787|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2021-04-16 05:40:07,787|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-04-16 05:40:07,787|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-04-16 05:40:07,787|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 8.630752563476562e-05 seconds.\\n\\n2021-04-16 05:40:07,787|azureml._SubmittedRun#predict-emailservice-xgboost_1618551593_b1da1b58.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2021-04-16 05:40:07,787|azureml.TrackFolders|DEBUG|[STOP]\\n2021-04-16 05:40:07,787|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2021-04-16 05:40:07,787|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2021-04-16 05:40:07,788|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2021-04-16 05:40:07,788|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-04-16 05:40:07,791|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:07,791|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2021-04-16 05:40:07,791|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2021-04-16 05:40:07,791|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,792|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,792|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,793|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,793|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,793|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,793|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,793|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,794|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,795|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,795|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,795|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,795|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,795|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,795|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,796|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,797|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,797|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,797|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,797|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,797|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,797|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,798|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,798|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,798|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,798|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,798|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,798|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,799|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,799|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,799|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,799|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,799|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-04-16 05:40:07,801|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result)].\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2021-04-16 05:40:07,805|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-04-16 05:40:07,806|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2021-04-16 05:40:07,806|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2021-04-16 05:40:07,806|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-04-16 05:40:07,806|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2021-04-16 05:40:08,056|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2021-04-16 05:40:08,056|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-04-16 05:40:08,056|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2021-04-16 05:40:08,056|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 2_result.\\n1 tasks left. Current duration of flush 0.00031566619873046875 seconds.\\n\\n2021-04-16 05:40:08,056|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.24.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get log results upon completion\n",
    "\n",
    "Model training and monitoring happen in the background. Wait until the model has finished training before you run more code. Use wait_for_completion to show when the model training is finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'predict-emailservice-xgboost_1618551593_b1da1b58',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-04-16T05:39:58.687472Z',\n",
       " 'endTimeUtc': '2021-04-16T05:40:14.123717Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'fc3ece24-ba9a-4631-907f-c2d9b8c962ea'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train_email_xgboost.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'user-managed-env-xgboost',\n",
       "   'version': 'Autosave_2021-03-26T03:58:54Z_11eca9d9',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'project_environment'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://csidmlws4729607923.blob.core.windows.net/azureml/ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=wtvs8SNr%2FrczpUbzzEkCT23LC3%2FhN7od%2B3zJwTY3nCg%3D&st=2021-04-16T05%3A30%3A16Z&se=2021-04-16T13%3A40%3A16Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://csidmlws4729607923.blob.core.windows.net/azureml/ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=xlfqImIQF7N%2FJikFFd%2FvGe9bQAZv5TDXJU7p9eppwUc%3D&st=2021-04-16T05%3A30%3A16Z&se=2021-04-16T13%3A40%3A16Z&sp=r',\n",
       "  'logs/azureml/4279_azureml.log': 'https://csidmlws4729607923.blob.core.windows.net/azureml/ExperimentRun/dcid.predict-emailservice-xgboost_1618551593_b1da1b58/logs/azureml/4279_azureml.log?sv=2019-02-02&sr=b&sig=7tHIfXH2sJqDoApbj022o9UrDtbNl2OHw10%2Fo7rqV0I%3D&st=2021-04-16T05%3A30%3A10Z&se=2021-04-16T13%3A40%3A10Z&sp=r'},\n",
       " 'submittedBy': 'Kok How Lee'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=False)  # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: All these calculations were run on your local machine, in the conda environment you defined above. You can find the results in:\n",
    "\n",
    "    + ~/.azureml/envs/azureml_xxxx for the conda environment you just created\n",
    "    + ~/AppData/Local/Temp/azureml_runs/train-on-local_xxxx for the machine learning models you trained (this path may differ depending on the platform you use). This folder also contains\n",
    "        - Logs (under azureml_logs/)\n",
    "        - Output pickled files (under outputs/)\n",
    "        - The configuration files (credentials, local and docker image setups)\n",
    "        - The train.py and mylib.py scripts\n",
    "        - The current notebook\n",
    "\n",
    "Take a few minutes to examine the output of the cell above. It shows the content of some of the log files, and extra information on the conda environment used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display run results\n",
    "\n",
    "Display the information captured by run.log(). Results will appear only after the run completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Connecting to api service': '<azure_search_client.azure_search_client object at 0x7fdbc03af2b0>', 'Setting up xgb params': \"{'objective': 'rank:ndcg', 'learning_rate': 0.5, 'min_child_weight': 0.1, 'max_depth': 10, 'n_estimators': 200}\", 'Predicted value counts': '3    142\\n5     84\\n1     56\\nName: pred_rating, dtype: int64', 'Exact Accuracy is': 0.5, 'Accuracy is': 0.67, 'End of run': 'Training completed'}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'objective': 'rank:ndcg', 'learning_rate': 0.5, 'min_child_weight': 0.1, 'max_depth': 10, 'n_estimators': 200}\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics('Setting up xgb params').get('Setting up xgb params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model\n",
    "\n",
    "The last step in the training script wrote the file outputs/predict-emailservice-xgbmodel.pkl in a directory named outputs in the VM of the cluster where the job is run. \"outputs\" is a special directory in that all content in this directory is automatically uploaded to your workspace. This content appears in the run record in the experiment under your workspace. So the model file is now also available in your workspace.\n",
    "\n",
    "You can see files associated with that run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/60_control_log.txt', 'azureml-logs/70_driver_log.txt', 'logs/azureml/4279_azureml.log', 'outputs/predict-emailservice-xgboostmodel.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the model in the workspace, so that you or other collaborators can later query, examine, and deploy this model. You can store the metrics you captured and store them into \"tags\" in the Model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict-emailservice-xgboostmodel\tpredict-emailservice-xgboostmodel:2\t2\t{'Setting up xgb params': \"{'objective': 'rank:ndcg', 'learning_rate': 0.5, 'min_child_weight': 0.1, 'max_depth': 10, 'n_estimators': 200}\", 'Predicted value counts': '3    142\\n5     84\\n1     56\\nName: pred_rating, dtype: int64', 'Exact Accuracy is': '0.5', 'Accuracy is': '0.67'}\n"
     ]
    }
   ],
   "source": [
    "# Adding metrics to tags so that these information can be used for model comparison purpose.\n",
    "# metrics = ['Accuracy','Precision','Recall','F1-score']\n",
    "metrics = ['Setting up xgb params', 'Predicted value counts', 'Exact Accuracy is', 'Accuracy is']\n",
    "\n",
    "tags = {}\n",
    "for key in metrics:\n",
    "    tags[key] = run.get_metrics(key).get(key)\n",
    "\n",
    "# register model, note the metric values are stored in \"tags\".\n",
    "model = run.register_model(model_name='predict-emailservice-xgboostmodel',\n",
    "                           model_path='outputs/predict-emailservice-xgboostmodel.pkl',\n",
    "                           tags=tags\n",
    "                          )\n",
    "print(model.name, model.id, model.version, model.tags, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have registered the model, you can proceed to Tutorial#2 to deploy the model."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "roastala"
   }
  ],
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "roastala",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
